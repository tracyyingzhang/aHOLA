{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7401645-5770-4432-83c3-55e4b1d3d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import contextlib\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import math\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf1820d-f3c6-4f63-a3ce-2e65ecb09dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    \"\"\"Context manager to patch joblib to report into tqdm progress bar given as argument\"\"\"\n",
    "\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d987b694-8cfa-4741-83af-98ee196161a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARG_LST = [\n",
    "    'posterior'\n",
    "]\n",
    "\n",
    "ALGO_LST = [\n",
    "    'LMC',\n",
    "    'LMCO',\n",
    "    'aHOLLA'\n",
    "]\n",
    "\n",
    "class LangevinSampler:\n",
    "    def __init__(self, targ, algo, step=0.001, beta=1, d=None):\n",
    "        assert targ in TARG_LST\n",
    "        assert algo in ALGO_LST\n",
    "        \n",
    "        self.targ = targ\n",
    "        self.algo = algo\n",
    "        self.step = step\n",
    "        self.beta = beta\n",
    "        self.d = d  # dimension of the parameter\n",
    "\n",
    "\n",
    "    def _exp(self, theta, x, cache=False):\n",
    "        z, y = x[:, :-1], x[:, -1]\n",
    "        if cache:\n",
    "            if not hasattr(self, '_exp_cache'):\n",
    "                self._exp_cache = np.exp(np.dot(z, theta))\n",
    "            return self._exp_cache\n",
    "        return np.exp(np.dot(z, theta))\n",
    "    \n",
    "    def _gradient(self, theta, x, cache=False):\n",
    "        z, y = x[:, :-1], x[:, -1]\n",
    "        exp_term = self._exp(theta, x, cache)\n",
    "        if self.targ == 'posterior':\n",
    "            return np.sum((1 - y[:, np.newaxis]) * z, axis=0) - np.sum(z / (1 + exp_term)[:, np.newaxis], axis=0) + theta\n",
    "\n",
    "    def _hessianvectorproduct(self, theta, x, cache=False):\n",
    "        z, _ = x[:, :-1], x[:, -1]\n",
    "        grad = self._gradient(theta, x, cache)\n",
    "        exp_term = self._exp(theta, x, cache)\n",
    "        if self.targ == 'posterior':\n",
    "            term = exp_term / (1 + exp_term) ** 2\n",
    "            hess_inner = term * np.dot(z, grad)   # Shape (N): Inner products <z_i,h>\n",
    "            hvp_term = np.dot(z.T, hess_inner)    # Shape (d): Sum_{i} <z_i,h>Â·z_i    \n",
    "            return grad + hvp_term\n",
    "\n",
    "    def _vectorlaplacian(self, theta, x, cache=False):\n",
    "        z, _ = x[:, :-1], x[:, -1]\n",
    "        exp_term = self._exp(theta, x, cache)\n",
    "        if self.targ == 'posterior':\n",
    "            norms_squared = np.linalg.norm(z, axis=1)**2\n",
    "            term = exp_term * (1 - exp_term) / (1 + exp_term)**3\n",
    "            return np.sum(z * norms_squared[:, np.newaxis] * term[:, np.newaxis], axis=0)\n",
    "\n",
    "    def _hessian_term(self, theta, x, cache=False):\n",
    "        if self.algo == 'LMC':\n",
    "            return 0\n",
    "        else:\n",
    "            return self._hessianvectorproduct(theta, x, cache)\n",
    "\n",
    "    def _vectorlaplacian_term(self, theta, x, cache=False):\n",
    "        if self.algo == 'aHOLLA':\n",
    "            return self._vectorlaplacian(theta, x, cache) / self.beta \n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def _hessiangauproducta(self, theta, x, cache=False):\n",
    "        z, _ = x[:, :-1], x[:, -1]\n",
    "        gau_a = np.random.standard_normal(self.d)\n",
    "        exp_term = self._exp(theta, x, cache)\n",
    "        if self.targ == 'posterior':\n",
    "            term = exp_term / (1 + exp_term)**2\n",
    "            \n",
    "            hess_inner = term * np.dot(z, gau_a)\n",
    "            hvp_term = np.dot(z.T, hess_inner) \n",
    "            return gau_a - self.step * (gau_a + hvp_term) / 2\n",
    "\n",
    "    def _hessiangauproductb(self, theta, x, cache=False):\n",
    "        z, _ = x[:, :-1], x[:, -1]\n",
    "        gau_b = np.random.standard_normal(self.d)\n",
    "        exp_term = self._exp(theta, x, cache)\n",
    "        if self.targ == 'posterior':\n",
    "            term = exp_term / (1 + exp_term)**2\n",
    "            \n",
    "            hess_inner = term * np.dot(z, gau_b)\n",
    "            hvp_term = np.dot(z.T, hess_inner) \n",
    "            return np.sqrt(3) / 6 * self.step * (gau_b + hvp_term)\n",
    "\n",
    "    \n",
    "    def _diffusion_term(self, theta, x, cache=False):\n",
    "        if self.algo == 'LMC':\n",
    "            return np.random.standard_normal(self.d)\n",
    "        else:\n",
    "            return self._hessiangauproducta(theta, x, cache) + self._hessiangauproductb(theta, x, cache)\n",
    "\n",
    "    \n",
    "    def sample(self, theta0, x, return_arr=True, runtime=200):\n",
    "        if runtime is not None:\n",
    "            n_iter = int(runtime/self.step)\n",
    "            n_burnin = n_iter\n",
    "            \n",
    "        theta = np.ravel(np.array(theta0).reshape(-1))\n",
    "        \n",
    "        if return_arr:\n",
    "            theta_arr = np.zeros((200, self.d))\n",
    "            \n",
    "        for n in np.arange(n_iter + n_burnin):\n",
    "            theta = theta + (- self.step * self._gradient(theta,x,cache=True) + \n",
    "                            (self.step ** 2 / 2) * self._hessian_term(theta,x,cache=True) - \n",
    "                            (self.step ** 2 / 2) * self._vectorlaplacian_term(theta,x,cache=True) + \n",
    "                            np.sqrt(2 * self.step / self.beta) * self._diffusion_term(theta,x,cache=True))\n",
    "            \n",
    "            if (n >= (n_iter + n_burnin - 200)) and return_arr:\n",
    "                index = n - (n_iter + n_burnin - 200)\n",
    "                theta_arr[index] = theta\n",
    "\n",
    "            # Clear cache after each iteration\n",
    "            if hasattr(self, '_exp_cache'):\n",
    "                del self._exp_cache\n",
    "\n",
    "        return theta if (not return_arr) else theta_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c4f45-3c18-4a5b-bd85-f9483124cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n, d, theta_true):\n",
    "    # Generate n d-dimensional standard Gaussian vectors\n",
    "    #z = np.random.normal(0, 1, (n, d))\n",
    "    z = np.random.choice([-1, 1], size=(n, d))\n",
    "    \n",
    "    # Calculate the parameter p for the Bernoulli random variables\n",
    "    p = np.exp(np.dot(z, theta_true)) / (1 + np.exp(np.dot(z, theta_true)))\n",
    "\n",
    "    # Generate y as Bernoulli random variables\n",
    "    y = np.random.binomial(1, p)\n",
    "\n",
    "    # Concatenate z and y into one matrix x\n",
    "    x = np.hstack((z, y.reshape(-1, 1)))  # Reshape y to be a column vector\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b16bb-c1bd-4826-9627-ac5cde962c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_samples_parallel(sampler, theta0, x, runtime=200, n_chains=50, n_jobs=-1):\n",
    "    d = len(np.ravel(np.array(theta0).reshape(-1)))\n",
    "    sampler.d = d\n",
    "\n",
    "    def _run_single_markov_chain():\n",
    "        return pd.DataFrame(\n",
    "            sampler.sample(theta0, x, runtime=runtime),\n",
    "            columns=[f'component_{i + 1}' for i in range(d)]\n",
    "        )\n",
    "\n",
    "    # Create a tqdm progress bar for the number of chains with specific description\n",
    "    with tqdm(total=n_chains, desc=f\"Running {algo} (d={d}, n={n}, step={step})\") as pbar:\n",
    "        with tqdm_joblib(pbar):\n",
    "            samples_df = Parallel(n_jobs=n_jobs)(\n",
    "                delayed(_run_single_markov_chain)() for _ in range(n_chains)\n",
    "            )\n",
    "\n",
    "    return pd.concat(samples_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8885b2-eb12-4b68-a4fe-e570948ecbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters\n",
    "n_values = [100, 200, 500]  # Different numbers of data points\n",
    "d_values = [5, 10, 20]  # Different values of d\n",
    "theta0 = None  # Will be defined inside the loop\n",
    "runtime = 500\n",
    "n_chains = 50\n",
    "step_sizes = [0.01]\n",
    "\n",
    "# Initialize results storage for means and MSE\n",
    "all_means = {}\n",
    "all_mse_results = {}\n",
    "all_running_times = {}\n",
    "\n",
    "# Run for each value of d\n",
    "for d in d_values:\n",
    "    for n in n_values:\n",
    "        theta_true = np.ones(d)\n",
    "        x = generate_data(n, d, theta_true)\n",
    "        \n",
    "        means = {algo: [] for algo in ALGO_LST}\n",
    "        mse_results = {algo: [] for algo in ALGO_LST}\n",
    "        running_times = {algo: [] for algo in ALGO_LST}\n",
    "        \n",
    "        # Run for each step size and each algorithm\n",
    "        for step in step_sizes:\n",
    "            for algo in ALGO_LST:\n",
    "                theta0 = 2 * np.ones(d)  # Initialize theta0 for the current d\n",
    "                sampler = LangevinSampler(targ='posterior', algo=algo, step=step, d=d)\n",
    "                \n",
    "                start_time = time.time()\n",
    "                samples_df = draw_samples_parallel(sampler, theta0, x, runtime=runtime, n_chains=n_chains)\n",
    "                end_time = time.time()\n",
    "                \n",
    "                # Compute mean of the samples for each chain\n",
    "                mean_samples = samples_df.groupby(samples_df.index // 200).mean().values\n",
    "                \n",
    "                # Calculate the MSE for the averaged means\n",
    "                mse = np.mean(np.linalg.norm((mean_samples - theta_true), axis=1) ** 2)\n",
    "                mse_results[algo].append(mse)\n",
    "                means[algo].append(mean_samples)\n",
    "                running_times[algo].append(end_time - start_time)\n",
    "\n",
    "        # Store results for this value of d and n\n",
    "        all_means[(d, n)] = means\n",
    "        all_mse_results[(d, n)] = mse_results\n",
    "        all_running_times[(d, n)] = running_times\n",
    "        \n",
    "        # Print MSE results for the current value of d\n",
    "        print(f\"\\nMSE Results for d={d} and n={n}:\")\n",
    "        mse_df = pd.DataFrame(all_mse_results[(d, n)], index=step_sizes)\n",
    "        mse_df.index.name = 'Step Size'\n",
    "        print(mse_df)\n",
    "        print(running_times)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
